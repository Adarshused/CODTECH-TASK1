## i have created an program for data preprocessing for transforming raw data into format suitable for building and training ai models

import pandas as pd
import numpy as np
from sklearn.impute import SimpleImputer 
from sklearn.preprocessing import OneHotEncoder 
from sklearn.preprocessing import MinMaxScaler,StandardScaler

## step-1 loading dataset
dataset=pd.read_csv('Data.csv') 
print("dataset before preprocessing: ")
print(dataset)

## step-2 finding missing values 
missing_values=dataset.isnull().sum()
# print(missing_values[missing_values>0])

## step-3 Encoding missing values
imputer=SimpleImputer(strategy= 'mean')

##applying imputer to numerical columns which has missing values
dataset[['Age','Salary']]=imputer.fit_transform(dataset[['Age','Salary']])


## applying imputer to categorical colns using OneHotEncoder
# 1) identifying the categorical_cols
categorical_col=['Country','Purchased']
## 2) creating obj for OneHotEncoder
encoder=OneHotEncoder( sparse_output=False ,drop='first')
## 3) converting categorical_col to numerical
encoded_feature=encoder.fit_transform(dataset[categorical_col])
encoded_feature_names=encoder.get_feature_names_out(categorical_col)
##creating new dataframe for encoded categorical cols
encoded_df=pd.DataFrame(encoded_feature,columns=encoded_feature_names)
## drop orginal categorical col from dataset
dataset=dataset.drop(categorical_col,axis=1)

dataset=pd.concat([dataset,encoded_df],axis=1)


## step-5 scaling
min_max_scaler=MinMaxScaler()
numerical_cols=['Age','Salary','Country_Antartica','Country_China','Country_India','Country_Indonesia','Country_Sri lanka','Country_nan','Purchased_Yes','Purchased_nan']

scaled_feature= min_max_scaler.fit_transform(dataset[numerical_cols])

scaled_df=pd.DataFrame(scaled_feature,columns=numerical_cols)
dataset[numerical_cols]=scaled_df

pd.set_option('display.max_columns',None)
pd.set_option('display.max_colwidth',None)
pd.set_option('display.expand_frame_repr',False)
print("dataset after preprocessing: ")
print(dataset)


